---
title: "K-NearestNeighbor - Predicting Bug Covering by Ranking"
author: "Christian Medeiros Adriano"
date: "August 6, 2017"
output: html_document
---

```{r setup, include=FALSE}
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_VotingAggregation//aggregateAnswerOptionsPerQuestion.R");
summaryTable <- runMain();

library(class);
library(gmodels);
library(caret);
library(e1071)
```

##Data preparation

#I need to guarantee that some examples (i.e., failing methods)
#do not dominate the training or testing sets. To do that, I need to get a 
#close to equal proportion of examples in both sets. I do that by 
#scrambling the data.

```{r dataprep}

set.seed(9850);
g<- runif((nrow(summaryTable))); #generates a random distribution
summaryTable <- summaryTable[order(g),];#reorder the rows based on a random index

#convert columns to numeric
summaryTable[,"rankingVote"] <- as.numeric(unlist(summaryTable[,"rankingVote"])); 
summaryTable[,"majorityVote"] <- as.numeric(unlist(summaryTable[,"majorityVote"])); 
summaryTable[,"thresholdVote"] <- as.numeric(unlist(summaryTable[,"thresholdVote"])); 

#Select only the ranking as a feature to predict bugCovering
summaryTable <- summaryTable[,c("bugCovering","rankingVote")];

#Prepare explanatory variable (rankingVote) and target (bugCovering)
trainingData <-data.frame(summaryTable);
trainingData$rankingVote <- as.numeric(trainingData$rankingVote);
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
```

## Build model with KNN wiht cross validation from package CLASS
```{r knn.cv.class}
#build model
#fitModel.cv <- knn.cv(train =trainingData, cl=trainingData$bugCovering, k=3, l=0, prob = FALSE, use.all=TRUE);
#fitModel.cv.df<-data.frame(fitModel.cv)
#CrossTable(x = trainingData$bugCovering, y=fitModel.cv.df[,1], prop.chisq = FALSE)
 
```
##Compute the minimal ranking value that corresponded to the predicted bugCovering questions
```{r knn.cv.ranking}
#trainingData$bugCovering <- as.factor(trainingData$bugCovering);
#predictedBugCoveringList<-trainingData[fitModel.cv.df[,1]==TRUE,];
#rankingList <- as.numeric(unlist(predictedBugCoveringList[,2]));
#mean(rankingList)
#max(rankingList)
#hist(rankingList,main="Bug-covering ranking dist., k=3, 5 or 7, knn Class, mean=1.71 ",xlab="ranking by number of YES");

```
### Using KNN from CARET package
# https://cran.r-project.org/web/packages/caret/vignettes/caret.pdf
# https://dataaspirant.com/2017/01/09/knn-implementation-r-using-caret-package/

# I will do 5 repeats of 10-Fold CV. I will fit
# a KNN model that evaluates 10 values of k
```{r knn.caret.model, echo=FALSE}

set.seed(1234)
trctrl <- trainControl(method = "repeatedcv", number=10, p=0.9, repeats = 5)

trainingData$rankingVote <- as.numeric(trainingData$rankingVote);
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
mean(trainingData$rankingVote);

knn_fit <- train(bugCovering ~ rankingVote, data = trainingData, method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)

bugCoveringPredicted <- predict(knn_fit,newdata = trainingData);

confusionMatrix(data=bugCoveringPredicted,trainingData$bugCovering)
 

```
##Compute the minimal ranking value that corresponded to the predicted bugCovering questions
```{r knn.caret.ranking, echo=FALSE}
df<-data.frame(bugCoveringPredicted)
predictedBugCoveringList<-trainingData[df[,1]==TRUE,];
rankingList <- as.numeric(unlist(predictedBugCoveringList[,2]));
mean(rankingList)
max(rankingList)
hist(rankingList,main="Bug-covering ranking dist., knn caret repeatedcv, mean=1.52, max=2",xlab="ranking by number of YES's");
```
#Caret produced more false positives than knn.cv from class package. I tried to fine tune it more,
#but was not enough. The k value for Caret seems very high 15 t 23.

