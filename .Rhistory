CrossTable(x = trainingData$bugCovering, y=fitModel.cv.df[,1], prop.chisq = FALSE)
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
predictedBugCoveringList<-trainingData[fitModel.cv.df[,1]==TRUE,];
predictedList <- as.numeric(unlist(predictedBugCoveringList[,2]));
mean(predictedList) #mean vote
min(predictedList) #highest ranking
max(predictedList) #lowest ranking
predictedList.df <- data.frame(predictedList);
colnames(predictedList.df)<- c("votes");
ggplot(data=predictedList.df, aes(x=predictedList.df$votes)) +
geom_histogram(binwidth = 0.5,alpha=.5, position="identity")+
geom_vline(aes(xintercept=mean(predictedList.df$votes, na.rm=T)),   # Ignore NA values for mean
color="red", linetype="dashed", size=1) +
ggtitle("Ranking of questions predicted as bug covering")+
labs(x="Ranking of YES votes of the questions categorized as bug-covering. lowest ranking=3, mean=1.71",
y="Frequency");
set.seed(1234)
trctrl <- trainControl(method = "repeatedcv", number=10, p=0.9, repeats = 5)
trainingData$rankingVote <- as.numeric(trainingData$rankingVote);
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
mean(trainingData$rankingVote);
knn_fit <- train(bugCovering ~ rankingVote, data = trainingData, method = "knn",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
bugCoveringPredicted <- predict(knn_fit,newdata = trainingData);
confusionMatrix(data=bugCoveringPredicted,trainingData$bugCovering)
df<-data.frame(bugCoveringPredicted)
predictedBugCoveringList<-trainingData[df[,1]==TRUE,];
rankingList <- as.numeric(unlist(predictedBugCoveringList[,2]));
mean(rankingList)
max(rankingList)
hist(rankingList,main="Bug-covering ranking dist., knn caret repeatedcv, mean=1.52, max=2",xlab="ranking by number of YES's");
?confusionMatrix
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_VotingAggregation//aggregateAnswerOptionsPerQuestion.R");
summaryTable <- runMain();
library(class);
library(gmodels);
library(caret);
library(e1071)
library(ggplot2);
set.seed(9850);
g<- runif((nrow(summaryTable))); #generates a random distribution
summaryTable <- summaryTable[order(g),];#reorder the rows based on a random index
#convert columns to numeric
summaryTable[,"rankingVote"] <- as.numeric(unlist(summaryTable[,"rankingVote"]));
#Select only the ranking as a feature to predict bugCovering
trainingData <- summaryTable[,c("bugCovering","rankingVote")];
trainingData$rankingVote <- as.numeric(trainingData$rankingVote);
#build model
fitModel.cv <- knn.cv(trainingData, trainingData$bugCovering, k=3, l=0, prob = FALSE, use.all=TRUE);
fitModel.cv.df<-data.frame(fitModel.cv);
CrossTable(x = trainingData$bugCovering, y=fitModel.cv.df[,1], prop.chisq = FALSE)
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
predictedBugCoveringList<-trainingData[fitModel.cv.df[,1]==TRUE,];
predictedList <- as.numeric(unlist(predictedBugCoveringList[,2]));
mean(predictedList) #mean vote
min(predictedList) #highest ranking
max(predictedList) #lowest ranking
predictedList.df <- data.frame(predictedList);
colnames(predictedList.df)<- c("votes");
ggplot(data=predictedList.df, aes(x=predictedList.df$votes)) +
geom_histogram(binwidth = 0.5,alpha=.5, position="identity")+
geom_vline(aes(xintercept=mean(predictedList.df$votes, na.rm=T)),   # Ignore NA values for mean
color="red", linetype="dashed", size=1) +
ggtitle("Ranking of questions predicted as bug covering")+
labs(x="Ranking of YES votes of the questions categorized as bug-covering. lowest ranking=3, mean=1.71",
y="Frequency");
set.seed(1234)
trctrl <- trainControl(method = "repeatedcv", number=10, p=0.9, repeats = 5)
trainingData$rankingVote <- as.numeric(trainingData$rankingVote);
trainingData$bugCovering <- as.factor(trainingData$bugCovering);
mean(trainingData$rankingVote);
knn_fit <- train(bugCovering ~ rankingVote, data = trainingData, method = "knn",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)
bugCoveringPredicted <- predict(knn_fit,newdata = trainingData);
confusionMatrix(data=bugCoveringPredicted,trainingData$bugCovering, mode="prec_recall", positive="TRUE")
df<-data.frame(bugCoveringPredicted)
predictedBugCoveringList<-trainingData[df[,1]==TRUE,];
rankingList <- as.numeric(unlist(predictedBugCoveringList[,2]));
mean(rankingList)
max(rankingList)
hist(rankingList,main="Bug-covering ranking dist., knn caret repeatedcv, mean=1.52, max=2",xlab="ranking by number of YES's");
library(caret)
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_VotingAggregation//aggregateAnswerOptionsPerQuestion.R");
summaryTable <- runMain();
#summaryTable <- data.frame(summaryTable);
#I need to guarantee that some examples (i.e., failing methods)
#do not dominate the training or testing sets. To do that, I need to get a
#close to equal proportion of examples in both sets
#Scramble the dataset before extracting the training set.
set.seed(8850);
g<- runif((nrow(summaryTable))); #generates a random distribution
summaryTable <- summaryTable[order(g),];
##################################################
# Create trainControl to be reused by all models #
#convert columns to numeric
summaryTable<- data.frame(summaryTable, stringsAsFactors = FALSE)
summaryTable[,"rankingVote"] <- as.numeric(unlist(summaryTable[,"rankingVote"]));
summaryTable[,"Yes.Count"] <- as.numeric(unlist(summaryTable[,"Yes.Count"]));
summaryTable[,"majorityVote"] <- as.numeric(unlist(summaryTable[,"majorityVote"]));
summaryTable$bugCoveringLabels <- as.character(summaryTable$bugCovering);
summaryTable$bugCoveringLabels<- replace(summaryTable$bugCoveringLabels,summaryTable$bugCoveringLabels=="FALSE", "F");
summaryTable$bugCoveringLabels<- replace(summaryTable$bugCoveringLabels,summaryTable$bugCoveringLabels=="TRUE", "T");
summaryTable$bugCoveringLabels<- as.factor(summaryTable$bugCoveringLabels);
# Create custom indices: myFolds
#Guarantees that we are going to use the exact
#same datasets for all models
myFolds <- createFolds(summaryTable[,"rankingVote"] , k = 15);
View(summaryTable)
View(summaryTable)
summaryTable[,"explanatoryVariable"] <- summaryTable[,"Yes.Count"];
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 15);
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
source("C://Users//chris//OneDrive//Documentos//GitHub//ML_VotingAggregation//aggregateAnswerOptionsPerQuestion.R");
summaryTable <- runMain();
#summaryTable <- data.frame(summaryTable);
#I need to guarantee that some examples (i.e., failing methods)
#do not dominate the training or testing sets. To do that, I need to get a
#close to equal proportion of examples in both sets
#Scramble the dataset before extracting the training set.
set.seed(8850);
g<- runif((nrow(summaryTable))); #generates a random distribution
summaryTable <- summaryTable[order(g),];
##################################################
# Create trainControl to be reused by all models #
#convert columns to numeric
summaryTable<- data.frame(summaryTable, stringsAsFactors = FALSE)
summaryTable[,"rankingVote"] <- as.numeric(unlist(summaryTable[,"rankingVote"]));
summaryTable[,"Yes.Count"] <- as.numeric(unlist(summaryTable[,"Yes.Count"]));
summaryTable[,"majorityVote"] <- as.numeric(unlist(summaryTable[,"majorityVote"]));
summaryTable[,"explanatoryVariable"] <- summaryTable[,"Yes.Count"];
summaryTable$bugCoveringLabels <- as.character(summaryTable$bugCovering);
summaryTable$bugCoveringLabels<- replace(summaryTable$bugCoveringLabels,summaryTable$bugCoveringLabels=="FALSE", "F");
summaryTable$bugCoveringLabels<- replace(summaryTable$bugCoveringLabels,summaryTable$bugCoveringLabels=="TRUE", "T");
summaryTable$bugCoveringLabels<- as.factor(summaryTable$bugCoveringLabels);
# Create custom indices: myFolds
#Guarantees that we are going to use the exact same datasets for all models
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 15);
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
knn <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="knn", trControl=kFoldControl);
rf<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="rf", trControl=kFoldControl);
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf");
predictedBugCoveringList<-compareTable[compareTable[,3]=="T",];
predictedBugCoveringList[,1]
rankingList
predictedBugCoveringList
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(glm,summaryTable),
predict(svmLinearWeights,summaryTable)
);
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(glmModel,summaryTable),
predict(svmLinearWeights,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf","glm","svm");
compareTable
predictedBugCoveringList<-compareTable[compareTable[,3]=="T",];
predictedBugCoveringList[,1]
rankingList
predictedBugCoveringList
summaryTable[,"explanatoryVariable"] <- summaryTable[,"majorityVote"];
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 15);
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
knn <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="knn", trControl=kFoldControl);
rf<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="rf", trControl=kFoldControl);
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(glmModel,summaryTable),
predict(svmLinearWeights,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf","glm","svm");
compareTable
predictedBugCoveringList<-compareTable[compareTable[,3]=="T",];
predictedBugCoveringList[,1]
compareTable[,1]
compareTable$nb
compareTable$glm
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
predictedBugCoveringList[,1]
head(predictedBugCoveringList)
predict(glm,summaryTable)
predict(glmModel,summaryTable)
predict(svmLinear,summaryTable$explanatoryVariable)
predict(glmModel,summaryTable$explanatoryVariable)
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
svmLinear <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear", trControl=kFoldControl);
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
bwplot(resampleList,metric="ROC")
densityplot(resampleList,metric="ROC")
dotplot(resampleList,xlim=range(0,1),metric="ROC")
twoBestList <- resamples(list(glm=glm,bayesglm=bayesglm));
xyplot(twoBestList,xlim=range(0,1), metric="ROC")
twoBestList <- resamples(list(glm=glmModel,bayesglm=bayesglm));
xyplot(twoBestList,xlim=range(0,1), metric="ROC")
predictedBugCoveringList<-compareTable[compareTable$knn=="T",];
predictedBugCoveringList[,1]
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
predictedBugCoveringList<-compareTable[compareTable$glmModel=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList<-compareTable[compareTable$glmModel=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
svmLinear
svmLinear2
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinear2
svmLinearWeights
bayesglm
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
glmModel
glmnet
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
glmModel
bayesglm
svmLinear <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear", trControl=kFoldControl);
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinear
svmLinear2
svmLinearWeights
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
bwplot(resampleList,metric="ROC")
dotplot(resampleList,xlim=range(0,1),metric="ROC")
predictedBugCoveringList<-compareTable[compareTable$svm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
predictedBugCoveringList<-compareTable[compareTable$knn=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 10);
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
knn <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="knn", trControl=kFoldControl);
rf<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="rf", trControl=kFoldControl);
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
glmModel
bayesglm
svmLinear <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear", trControl=kFoldControl);
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinear
svmLinear2
svmLinearWeights
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(glmModel,summaryTable),
predict(svmLinearWeights,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf","glm","svm");
compareTable
predictedBugCoveringList<-compareTable[compareTable$knn=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
#Computing the miminum ranking value
min(predictedBugCoveringList$explanatoryVariable);
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
bwplot(resampleList,metric="ROC")
dotplot(resampleList,xlim=range(0,1),metric="ROC")
twoBestList <- resamples(list(svmLinearWeights=svmLinearWeights,bayesglm=bayesglm));
xyplot(twoBestList,xlim=range(0,1), metric="ROC")
secodThirdBestList <- resamples(list(knn=knn,bayesglm=bayesglm));
xyplot(twoBestList,xlim=range(0,1), metric="ROC")
secodThirdBestList <- resamples(list(knn=knn,bayesglm=bayesglm));
xyplot(secodThirdBestList,xlim=range(0,1), metric="ROC")
predictedBugCoveringList<-compareTable[compareTable$bayesglm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
predictedBugCoveringList
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(bayesglm,summaryTable),
predict(svmLinearWeights,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf","glm","svm");
compareTable
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
min(predictedBugCoveringList$explanatoryVariable);
svmLinearWeights
knn <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="knn", trControl=kFoldControl);
knn
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
rf<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="rf", trControl=kFoldControl);
rf
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
glmModel
glmBoost<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmBoost", trControl=kFoldControl);
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
bayesglm
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
glmnet<- train(data.matrix(bugCoveringLabels) ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
glmnet<- train(data.matrix(bugCoveringLabels) ~ data.matrix(explanatoryVariable),summaryTable, method="glmnet", trControl=kFoldControl);
glmnet<- train(data.matrix(bugCoveringLabels) ~ data.matrix(explanatoryVariable),data.matrix(summaryTable), method="glmnet", trControl=kFoldControl);
glmnet
glmnetModel<- train(data.matrix(bugCoveringLabels) ~ data.matrix(explanatoryVariable),data.matrix(summaryTable), method="glmnet", trControl=kFoldControl);
glmnetModel
svmLinear <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear", trControl=kFoldControl);
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinear
svmLinear2
svmLinearWeights
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinearWeights
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinearWeights
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
bwplot(resampleList,metric="ROC")
densityplot(resampleList,metric="ROC")
dotplot(resampleList,xlim=range(0,1),metric="ROC")
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 5);
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
knn <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="knn", trControl=kFoldControl);
knn
rf<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="rf", trControl=kFoldControl);
rf
glmModel<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glm", trControl=kFoldControl);
glmModel
bayesglm<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="bayesglm", trControl=kFoldControl);
bayesglm
glmnet<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="glmnet", trControl=kFoldControl);
svmLinear <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear", trControl=kFoldControl);
svmLinear2 <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinear2", trControl=kFoldControl);
svmLinearWeights <- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="svmLinearWeights", trControl=kFoldControl);
svmLinear
svmLinear2
svmLinearWeights
resampleList<-resamples(list(svmLinear=svmLinear,svmLinear2=svmLinear2,svmLinearWeights=svmLinearWeights,
glm=glmModel,bayesglm=bayesglm, rf=rf, knn=knn, nb=nb
));
dotplot(resampleList,xlim=range(0,1),metric="ROC")
twoBestList <- resamples(list(svmLinearWeights=svmLinearWeights,bayesglm=bayesglm));
xyplot(twoBestList,xlim=range(0,1), metric="ROC")
secodThirdBestList <- resamples(list(knn=knn,bayesglm=bayesglm));
xyplot(secodThirdBestList,xlim=range(0,1), metric="ROC")
compareTable <- data.frame(summaryTable$explanatoryVariable,
summaryTable$bugCoveringLabels,
predict(nb,summaryTable),
predict(knn,summaryTable),
predict(rf,summaryTable),
predict(bayesglm,summaryTable),
predict(svmLinearWeights,summaryTable)
);
colnames(compareTable) <- c("explanatoryVariable","actual","nb","knn","rf","glm","svm");
compareTable
predictedBugCoveringList<-compareTable[compareTable$glm=="T",];
predictedBugCoveringList$explanatoryVariable
predictedBugCoveringList
#Computing the miminum value of n that predicted bugCovering True
min(predictedBugCoveringList$explanatoryVariable);
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 5);
# Create reusable trainControl object: myControl
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
#######################
# Generate each model #
##############
# Naive Bayes
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 10);
# Create reusable trainControl object: myControl
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
#######################
# Generate each model #
##############
# Naive Bayes
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 3);
# Create reusable trainControl object: myControl
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
#######################
# Generate each model #
##############
# Naive Bayes
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
myFolds <- createFolds(summaryTable[,"explanatoryVariable"] , k = 12);
# Create reusable trainControl object: myControl
kFoldControl <- trainControl(
index = myFolds, #Train with 9 folds and validate with one
classProbs = TRUE, # IMPORTANT!
verboseIter = TRUE, #
savePredictions = TRUE, #
summaryFunction = twoClassSummary
);
#######################
# Generate each model #
##############
# Naive Bayes
nb<- train(bugCoveringLabels ~ explanatoryVariable,summaryTable, method="nb", trControl=kFoldControl);
nb
